import torch
import torch.nn.functional as F
import torch.nn as nn
import tqdm

@torch.no_grad()
def evaluate(model, val_loader):
    model.eval()
    outputs = [model.validation_step(batch) for batch in val_loader]
    return model.validation_epoch_end(outputs)

def get_lr(optimizer):
    for param_group in optimizer.param_groups:
        return param_group['lr']

def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, 
                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):
    torch.cuda.empty_cache()
    history = []
    
    # Set up cutom optimizer with weight decay
    #optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay, momentum=0.9)
    optimizer = opt_func(model.parameters(), max_lr) #for adam
    # Set up one-cycle learning rate scheduler
    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, base_momentum = 0.8, steps_per_epoch=len(train_loader))
    #sched = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)
    #sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4 )
    #sched = torch.optim.lr_scheduler.CyclicLR(optimizer, max_lr=max_lr, base_lr=0.00001, step_size_up=50, step_size_down=len(train_loader)*3, cycle_momentum=False)
    best_acc = 0.0
    for epoch in range(epochs):
        # Training Phase 
        model.train()
        train_losses = []
        lrs = []
        for batch in tqdm(train_loader):
            loss = model.training_step(batch)
            train_losses.append(loss)
            loss.backward()
            
            # Gradient clipping
            if grad_clip: 
                nn.utils.clip_grad_value_(model.parameters(), grad_clip)
            
            optimizer.step()
            optimizer.zero_grad()
            
            # Record & update learning rate
            lrs.append(get_lr(optimizer))
            
            sched.step()
            
        
        # Validation phase
        result = evaluate(model, val_loader)
        result['train_loss'] = torch.stack(train_losses).mean().item()
        result['lrs'] = lrs
        model.epoch_end(epoch, result)
        if best_acc < result['val_score'] :
            best_acc = result['val_score']
            torch.save(model.state_dict(), 'best-epoch.pth')
        history.append(result)
    print(f'best accuracy = {best_acc}')
    return history